{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB | Imbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the data**\n",
    "\n",
    "In this challenge, we will be working with Credit Card Fraud dataset.\n",
    "\n",
    "https://raw.githubusercontent.com/data-bootcamp-v4/data/main/card_transdata.csv\n",
    "\n",
    "Metadata\n",
    "\n",
    "- **distance_from_home:** the distance from home where the transaction happened.\n",
    "- **distance_from_last_transaction:** the distance from last transaction happened.\n",
    "- **ratio_to_median_purchase_price:** Ratio of purchased price transaction to median purchase price.\n",
    "- **repeat_retailer:** Is the transaction happened from same retailer.\n",
    "- **used_chip:** Is the transaction through chip (credit card).\n",
    "- **used_pin_number:** Is the transaction happened by using PIN number.\n",
    "- **online_order:** Is the transaction an online order.\n",
    "- **fraud:** Is the transaction fraudulent. **0=legit** -  **1=fraud**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>distance_from_last_transaction</th>\n",
       "      <th>ratio_to_median_purchase_price</th>\n",
       "      <th>repeat_retailer</th>\n",
       "      <th>used_chip</th>\n",
       "      <th>used_pin_number</th>\n",
       "      <th>online_order</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57.877857</td>\n",
       "      <td>0.311140</td>\n",
       "      <td>1.945940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.829943</td>\n",
       "      <td>0.175592</td>\n",
       "      <td>1.294219</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.091079</td>\n",
       "      <td>0.805153</td>\n",
       "      <td>0.427715</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.247564</td>\n",
       "      <td>5.600044</td>\n",
       "      <td>0.362663</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44.190936</td>\n",
       "      <td>0.566486</td>\n",
       "      <td>2.222767</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   distance_from_home  distance_from_last_transaction  \\\n",
       "0           57.877857                        0.311140   \n",
       "1           10.829943                        0.175592   \n",
       "2            5.091079                        0.805153   \n",
       "3            2.247564                        5.600044   \n",
       "4           44.190936                        0.566486   \n",
       "\n",
       "   ratio_to_median_purchase_price  repeat_retailer  used_chip  \\\n",
       "0                        1.945940              1.0        1.0   \n",
       "1                        1.294219              1.0        0.0   \n",
       "2                        0.427715              1.0        0.0   \n",
       "3                        0.362663              1.0        1.0   \n",
       "4                        2.222767              1.0        1.0   \n",
       "\n",
       "   used_pin_number  online_order  fraud  \n",
       "0              0.0           0.0    0.0  \n",
       "1              0.0           0.0    0.0  \n",
       "2              0.0           1.0    0.0  \n",
       "3              0.0           1.0    0.0  \n",
       "4              0.0           1.0    0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud = pd.read_csv(\"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/card_transdata.csv\")\n",
    "fraud.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Steps:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **1.** What is the distribution of our target variable? Can we say we're dealing with an imbalanced dataset?\n",
    "- **2.** Train a LogisticRegression.\n",
    "- **3.** Evaluate your model. Take in consideration class importance, and evaluate it by selection the correct metric.\n",
    "- **4.** Run **Oversample** in order to balance our target variable and repeat the steps above, now with balanced data. Does it improve the performance of our model? \n",
    "- **5.** Now, run **Undersample** in order to balance our target variable and repeat the steps above (1-3), now with balanced data. Does it improve the performance of our model?\n",
    "- **6.** Finally, run **SMOTE** in order to balance our target variable and repeat the steps above (1-3), now with balanced data. Does it improve the performance of our model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "fraud\n",
       "0.0    912597\n",
       "1.0     87403\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1\n",
    "f_df = fraud[\"fraud\"].value_counts()\n",
    "f_df.plot(kind=\"bar\")\n",
    "plt.show()\n",
    "f_df\n",
    "#The distribution is highly imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.99      0.98    228142\n",
      "         1.0       0.90      0.60      0.72     21858\n",
      "\n",
      "    accuracy                           0.96    250000\n",
      "   macro avg       0.93      0.80      0.85    250000\n",
      "weighted avg       0.96      0.96      0.96    250000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2 \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "features = fraud.drop(columns = \"fraud\")\n",
    "target = fraud[\"fraud\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "log_reg.score(X_test_scaled, y_test)\n",
    "pred = log_reg.predict(X_test_scaled)\n",
    "print(classification_report(y_pred = pred, y_true = y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 We can see with recall precision and f1-score that the model identifies really well the fraud= 0 (as the sample is really big) but c¡for the fraud=1 it doesn't (as the sample is lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.93      0.96    228142\n",
      "         1.0       0.58      0.95      0.72     21858\n",
      "\n",
      "    accuracy                           0.93    250000\n",
      "   macro avg       0.79      0.94      0.84    250000\n",
      "weighted avg       0.96      0.93      0.94    250000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlescampdepadrosmartin/opt/anaconda3/envs/base2/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/carlescampdepadrosmartin/opt/anaconda3/envs/base2/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "from sklearn.utils import resample\n",
    "\n",
    "train = pd.DataFrame(X_train_scaled, columns = X_train.columns)\n",
    "train[\"fraud\"] = y_train.values\n",
    "fraud_1 = train[train[\"fraud\"] == 1]\n",
    "fraud_0 = train[train[\"fraud\"] == 0]\n",
    "len(fraud_0), len(fraud_1)\n",
    "oversampled = resample(fraud_1, replace=True, n_samples = len(fraud_0))\n",
    "fraud_over = pd.concat([oversampled, fraud_0])\n",
    "\n",
    "X_train_over = fraud_over.drop(columns = [\"fraud\"])\n",
    "y_train_over = fraud_over[\"fraud\"]\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_over, y_train_over)\n",
    "log_reg.score(X_test_scaled, y_test)\n",
    "pred = log_reg.predict(X_test_scaled)\n",
    "print(classification_report(y_pred = pred, y_true = y_test))\n",
    "#It improves in terms of recall for the fraud = 1 as we oversampled, but for the other metrics it stays the same or worst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.93      0.96    228142\n",
      "         1.0       0.58      0.95      0.72     21858\n",
      "\n",
      "    accuracy                           0.93    250000\n",
      "   macro avg       0.79      0.94      0.84    250000\n",
      "weighted avg       0.96      0.93      0.94    250000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlescampdepadrosmartin/opt/anaconda3/envs/base2/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/carlescampdepadrosmartin/opt/anaconda3/envs/base2/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 5\n",
    "undersampled = resample(fraud_0, replace=True, n_samples = len(fraud_1))\n",
    "fraud_under = pd.concat([undersampled, fraud_1])\n",
    "X_train_under = fraud_under.drop(columns = \"fraud\")\n",
    "y_train_under = fraud_under[\"fraud\"]\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_under, y_train_under)\n",
    "log_reg.score(X_test_scaled, y_test)\n",
    "pred = log_reg.predict(X_test_scaled)\n",
    "print(classification_report(y_pred = pred, y_true = y_test))\n",
    "#We are getting similar results as the oversampling method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.93      0.96    228142\n",
      "         1.0       0.58      0.95      0.72     21858\n",
      "\n",
      "    accuracy                           0.93    250000\n",
      "   macro avg       0.79      0.94      0.84    250000\n",
      "weighted avg       0.96      0.93      0.94    250000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state = 1,sampling_strategy=1.0)\n",
    "X_train_sm,y_train_sm = sm.fit_resample(X_train_scaled,y_train)\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train_sm, y_train_sm)\n",
    "pred = log_reg.predict(X_test_scaled)\n",
    "print(classification_report(y_pred = pred, y_true = y_test))\n",
    "#We are getting similar results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
